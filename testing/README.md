# Testing Procedure

While developing the ANTLR grammar, this directory is used for testing coverage. Everything is
command-line driven.

Unlike the “production” processor in the parent directory, which works with the
Python code generated by ANTLR, this directory works with the Java code it generates. The Java code
is a bit faster, and it provides better support for tracking down problems when things go awry.

## `generate_test_data.py`

This script pulls the current set of Scribe Blocks from the local database, and saves them as text
files in a set of subdirectories named `test_data.major`, `test_data.minor`, `test_data.conc`
(_concentration_), `test_data.degree`, and `test_data.other`. It consults the contents of
_quarantine\_list_ (see below) and puts those blocks in `test_data.quarantine` instead.

## `run_tests`

This script tries to parse all the scribe blocks in the five not-quarantine test_data directories,
with command arguments for selecting only some of them, or the _quarantine_ option for testing
whether or not the quarantined blocks have been fixed since they were quarantined.

Anything that fails to parse will generate an entry in the corresponding `test\_results.xxx` dir.

This script also generates a CSV report telling how long it took to parse each block. Some blocks,
especially malformed ones can take a very long time to parse, and there is a configurable time limit
that controls how long the parser will be allowed to work on a block.

## Environment Variables and Aliases

These are set up from my login script (`~/.aliases_du_jour`):

    # While testing dgw parser
    export testing="/Users/vickery/Projects/dgw_processor/testing"
    alias testing='cd "$testing"'
    alias setit='export TEST_DATA=$TEST_DIR/`pbpaste`'
    alias tot='export saved_t=$TEST_DATA; cp $TEST_DATA ./t; export TEST_DATA=./t'
    alias fromt='export TEST_DATA=$saved_t'
    alias sublt='subl t'
    alias lt='echo $TEST_DIR; ls -l $TEST_DIR'
    alias lr='echo $RESULT_DIR; ls -lS $RESULT_DIR|m'
    alias vr='m $RESULT_DIR/`pbpaste`'
    function use {
      export TEST_DIR=test_data.$1
      export RESULT_DIR=test_results.$1
    }
    use major

## Examining Problems And Quarantining Miscreants

The _use_ function selects a block type to examine; the `use major` command at the end of the login
script makes _test\_data.major_ and _test\_results.major_ the default subdirectories. The _lr_
command lets you list the blocks that caused problems. Select the name of the file to work with from
that list, and use the _setit_ command to copy the pathname to the clipboard. Then use the _tot_
command to copy the file itself to the temporary file named _./t_. Use _sublt_ to open the file in
the Sublime text editor. If you decide the block has a syntax error, use the `quarantine` command to
add it to the _quarantine\_list_. See that file for the expected format of the explanation to enter.

The _quarantine\_list_ is used in two ways: one is that `generate\_test_data.py` uses it to put
blocks with known problems in the _test\_data.quarantine_ directory rather than one of the “normal”
ones (major, minor, conc, degree, other). The Python routines in the parent directory also use
it to skip the miscreants from being processed there.

## The _Makefile_

Use the POSIX _make_ command to debug scribe blocks and/or the grammar. The _parser_ target
generates the Java lexer and parser code, and will be invoked whenever _ReqBlock.g4_ changes. The
default target processes the scribe block in the _./t_ temporary file. If there is no output, that
means the block parsed without a problem. Otherwise, use the text editor to delete portions of the
scribe block and/or to make changes in it to locate the code that is causing parsing to fail. The
_tokens_ target shows what tokens the ANTLR runtime found in the block, in the sequence they
appeared. If the block parses okay but you want to be sure the grammar is accurate, _gui_ target
puts up an interactive picture of the parse tree. (A very cool feature of ANTLR.)
